{"componentChunkName":"component---src-pages-index-tsx","path":"/","result":{"data":{"header":{"childImageSharp":{"fixed":{"base64":"data:image/jpeg;base64,/9j/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wgARCAAPABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABAAD/8QAFgEBAQEAAAAAAAAAAAAAAAAAAQID/9oADAMBAAIQAxAAAAFT8FZ2O0k//8QAGhAAAgMBAQAAAAAAAAAAAAAAAQMAAgQREv/aAAgBAQABBQKjlSrlWB3ZwVme5ynf/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAHBAAAQMFAAAAAAAAAAAAAAAAAQAxMgIQERIh/9oACAEBAAY/ApI4qbiI3a8Qv//EABkQAQADAQEAAAAAAAAAAAAAAAEAESExQf/aAAgBAQABPyFye1oxjlfa2PYhNKuSmOIolve5P//aAAwDAQACAAMAAAAQ/wAv/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGxABAAMAAwEAAAAAAAAAAAAAAQARITFhgVH/2gAIAQEAAT8QM2iidk8gDBxpXxpKEyFur6g1K8mkDHnuOkNaTaz/2Q==","width":2000,"height":1500,"src":"/static/61333c450e3d49c0054f6a6f26c26acd/a66ad/diffuse.jpg","srcSet":"/static/61333c450e3d49c0054f6a6f26c26acd/a66ad/diffuse.jpg 1x,\n/static/61333c450e3d49c0054f6a6f26c26acd/d9c19/diffuse.jpg 1.5x,\n/static/61333c450e3d49c0054f6a6f26c26acd/ff044/diffuse.jpg 2x"}}},"allMarkdownRemark":{"edges":[{"node":{"timeToRead":4,"frontmatter":{"title":"Three Phase Commit Data Migrations","date":"2018-12-09T19:35:54.000Z","tags":["Technique","Software Engineering"]},"excerpt":"Paving a path towards continuous delivery and zero-downtime deployments is a challenging pursuit especially when each project employs its…","html":"<p>Paving a path towards continuous delivery and zero-downtime deployments is a challenging pursuit especially when each project employs its own strategy.\nOne generic solution that is at the heart of this article was inspired by the three-phase-commit.\nIts origin stems from <em>computer networking</em> as a way to perform the non-blocking version of the two-phase commit protocol, described as:</p>\n<ol>\n<li>voting phase: a coordinator prepares all transaction participants, signaling to proceed until either committing or aborting.</li>\n<li>commit phase: depending on participant votes, the coordinator decides to <em>commit</em> if all voted <em>agree</em> otherwise it <em>aborts</em> and notifies all participants.</li>\n</ol>\n<p>Adapting these to web applications, the <em>contention</em> for <em>resources</em> occurs with respect to databases and long-lived state.\nTaking downtime is commonly due to blocking operations from locking mechanisms over shared resources.\nTo ensure the stability of an application’s environment while updating, taking downtime will guarantee <em>state</em> remains consistent for all services and users.\nSince causes for downtime can be determined in advance, using more sophisticated approaches to eliminate it is possible.\nExecuting data migrations as three distinct phases is a generic approach that anyone can use as a stone to pave in the road to zero-downtime deployments.</p>\n<h2>Assemble Phase</h2>\n<p>The first phase involves the creation of new entities which usually means new tables or columns with respect to a database.\nWhen a new entity replaces an old one the use of dual writes and idempotent operations is an effective strategy.\nDual writes are when both old and new entities are recorded in the database alongside the running application.\nIt allows changes to happen in production while still being able to roll-back those changes to the old model should the need arise.\nThis increases the reliability that the updates work as intended and without issue.\nMaking the new entity operations idempotent is also very valuable in many cases as we’ll find in the next phase.\nFor an application, data structures that replace old ones are a common source failure.\nBy the creation of an idempotent legacy handler, it’s possible to create a version chain that’s able to turn an old structure into a new one reliably.\nHaving multiple versions of data and data structures is not ideal, but it is not always practical to migrate all data in one shot.\nBy having a type of JIT version update in place, it’s possible to avoid complexities around more sophisticated data migrations.</p>\n<h2>Manipulation Phase</h2>\n<p>Back-filling data into a newly created column is the essence of this phase.\nProcessing data only requires a read from an old entity and a write to the new one.\nHow those writes are performed matters greatly.\nThe trivial approach to writing a data migration is to do everything in one shot with no roll-back plan.\nIt’s not always possible or at least practical to build database roll-back plans.\nWhen failures occur with single pass migrations, they can be very expensive.\nThe database might have locked some critical columns with a large number of rows.\nSo whatever the downtime is for a successful operation always needs to be planned to be double just in case a rollback is required.</p>\n<p>Alternatively, when writing operations are made idempotent the application can be made eventually consistent.\nSince dual writing new data is already occurring, backfilling old data into the new format using an idempotent write operation allows the application to fail safely.\nA write might fail for many reasons — junk data, unexpected formats, and mishandled cases.\nImagine having the first <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>75</mn></mrow><annotation encoding=\"application/x-tex\">75%</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">7</span><span class=\"mord\">5</span></span></span></span> of a migration be performed and then fail on a single valid case.\nThere are a few potential issues here:</p>\n<ol>\n<li>the backfill task is performed as a migration</li>\n<li>the backfill task is performed as a transaction</li>\n<li>the backfill task is not idempotent</li>\n</ol>\n<p>The first case has the flaw of downtime.\nThe second issue may be computationally expensive and infeasible to repeatedly perform.\nThe last issue creates potential for duplicated data during the backfill process.\nUsing the idempotent strategy is more manageable since backfilling doesn’t need to occur all at once.\nIf multiple write operations do happen, they end in the same result.\nFlexible data migrations are the result.\nMigrations can be written so that they’re performed in one shot or done as batch jobs.\nThe failure handling mechanisms can also be as simple or complex as desired.\nFor instance, using a trivial approach to retry the entire backfill or a sophisticated one to pick up where it left off.</p>\n<h2>Dismantle Phase</h2>\n<p>This is equivalent to dropping an entity from the database.\nWith the completion of the <em>manipulation phase</em>, getting verification that the backfill is complete is necessary to confirm the entity is no longer required.\nAll the code that handled the updates and branching paths that resulted from different version functions can be removed too.\nThere’s no better feeling as an engineer than reducing all the complexity of a system by removing the bloat and scaffolding that’s no longer needed.</p>\n<h2>All Good Things</h2>\n<p>A final word of caution.\nApplication code updates only work reliably when the state of the application can be rebuilt and executed in the event of a crash.\nOne approach is to build a history from immutable states which can be replayed, basically a log in the way some file systems work.\nIf the behavior of an application is determined by global state that cannot be restored reliably, larger problems exist and this strategy is unlikely to help.\nOther problems that were not covered include the existence of operating on data across different databases.\nThis is a much harder distributed systems problem to solve but using idempotent operations is a great place to start.</p>\n<p>The three phase commit strategy has worked on production systems for a few years in a variety of different scenarios.\nPreviously, deployments would happen during the odd hours of evening in order to cause minimal disruption.\nZero-downtime deployments can happen during sane working ours bringing joy to engineers, more certainty to stake holders, and a better experience for customers.\nAll good things result for all parties that have a lot to loose when things go wrong.</p>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Paving a path towards continuous delivery and zero-downtime deployments is a challenging pursuit especially when each project employs its own strategy.\nOne generic solution that is at the heart of this article was inspired by the three-phase-commit.\nIts origin stems from "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"computer networking"}]},{"type":"text","value":" as a way to perform the non-blocking version of the two-phase commit protocol, described as:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"voting phase: a coordinator prepares all transaction participants, signaling to proceed until either committing or aborting."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"commit phase: depending on participant votes, the coordinator decides to "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"commit"}]},{"type":"text","value":" if all voted "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"agree"}]},{"type":"text","value":" otherwise it "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"aborts"}]},{"type":"text","value":" and notifies all participants."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Adapting these to web applications, the "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"contention"}]},{"type":"text","value":" for "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"resources"}]},{"type":"text","value":" occurs with respect to databases and long-lived state.\nTaking downtime is commonly due to blocking operations from locking mechanisms over shared resources.\nTo ensure the stability of an application’s environment while updating, taking downtime will guarantee "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"state"}]},{"type":"text","value":" remains consistent for all services and users.\nSince causes for downtime can be determined in advance, using more sophisticated approaches to eliminate it is possible.\nExecuting data migrations as three distinct phases is a generic approach that anyone can use as a stone to pave in the road to zero-downtime deployments."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Assemble Phase"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The first phase involves the creation of new entities which usually means new tables or columns with respect to a database.\nWhen a new entity replaces an old one the use of dual writes and idempotent operations is an effective strategy.\nDual writes are when both old and new entities are recorded in the database alongside the running application.\nIt allows changes to happen in production while still being able to roll-back those changes to the old model should the need arise.\nThis increases the reliability that the updates work as intended and without issue.\nMaking the new entity operations idempotent is also very valuable in many cases as we’ll find in the next phase.\nFor an application, data structures that replace old ones are a common source failure.\nBy the creation of an idempotent legacy handler, it’s possible to create a version chain that’s able to turn an old structure into a new one reliably.\nHaving multiple versions of data and data structures is not ideal, but it is not always practical to migrate all data in one shot.\nBy having a type of JIT version update in place, it’s possible to avoid complexities around more sophisticated data migrations."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Manipulation Phase"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Back-filling data into a newly created column is the essence of this phase.\nProcessing data only requires a read from an old entity and a write to the new one.\nHow those writes are performed matters greatly.\nThe trivial approach to writing a data migration is to do everything in one shot with no roll-back plan.\nIt’s not always possible or at least practical to build database roll-back plans.\nWhen failures occur with single pass migrations, they can be very expensive.\nThe database might have locked some critical columns with a large number of rows.\nSo whatever the downtime is for a successful operation always needs to be planned to be double just in case a rollback is required."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Alternatively, when writing operations are made idempotent the application can be made eventually consistent.\nSince dual writing new data is already occurring, backfilling old data into the new format using an idempotent write operation allows the application to fail safely.\nA write might fail for many reasons — junk data, unexpected formats, and mishandled cases.\nImagine having the first "},{"type":"element","tagName":"span","properties":{"className":["katex"]},"children":[{"type":"element","tagName":"span","properties":{"className":["katex-mathml"]},"children":[{"type":"element","tagName":"math","properties":{},"children":[{"type":"element","tagName":"semantics","properties":{},"children":[{"type":"element","tagName":"mrow","properties":{},"children":[{"type":"element","tagName":"mn","properties":{},"children":[{"type":"text","value":"75"}]}]},{"type":"element","tagName":"annotation","properties":{"encoding":"application/x-tex"},"children":[{"type":"text","value":"75%"}]}]}]}]},{"type":"element","tagName":"span","properties":{"className":["katex-html"],"ariaHidden":"true"},"children":[{"type":"element","tagName":"span","properties":{"className":["base"]},"children":[{"type":"element","tagName":"span","properties":{"className":["strut"],"style":"height:0.64444em;vertical-align:0em;"},"children":[]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"text","value":"7"}]},{"type":"element","tagName":"span","properties":{"className":["mord"]},"children":[{"type":"text","value":"5"}]}]}]}]},{"type":"text","value":" of a migration be performed and then fail on a single valid case.\nThere are a few potential issues here:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"the backfill task is performed as a migration"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"the backfill task is performed as a transaction"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"the backfill task is not idempotent"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The first case has the flaw of downtime.\nThe second issue may be computationally expensive and infeasible to repeatedly perform.\nThe last issue creates potential for duplicated data during the backfill process.\nUsing the idempotent strategy is more manageable since backfilling doesn’t need to occur all at once.\nIf multiple write operations do happen, they end in the same result.\nFlexible data migrations are the result.\nMigrations can be written so that they’re performed in one shot or done as batch jobs.\nThe failure handling mechanisms can also be as simple or complex as desired.\nFor instance, using a trivial approach to retry the entire backfill or a sophisticated one to pick up where it left off."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Dismantle Phase"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"This is equivalent to dropping an entity from the database.\nWith the completion of the "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"manipulation phase"}]},{"type":"text","value":", getting verification that the backfill is complete is necessary to confirm the entity is no longer required.\nAll the code that handled the updates and branching paths that resulted from different version functions can be removed too.\nThere’s no better feeling as an engineer than reducing all the complexity of a system by removing the bloat and scaffolding that’s no longer needed."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"All Good Things"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"A final word of caution.\nApplication code updates only work reliably when the state of the application can be rebuilt and executed in the event of a crash.\nOne approach is to build a history from immutable states which can be replayed, basically a log in the way some file systems work.\nIf the behavior of an application is determined by global state that cannot be restored reliably, larger problems exist and this strategy is unlikely to help.\nOther problems that were not covered include the existence of operating on data across different databases.\nThis is a much harder distributed systems problem to solve but using idempotent operations is a great place to start."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The three phase commit strategy has worked on production systems for a few years in a variety of different scenarios.\nPreviously, deployments would happen during the odd hours of evening in order to cause minimal disruption.\nZero-downtime deployments can happen during sane working ours bringing joy to engineers, more certainty to stake holders, and a better experience for customers.\nAll good things result for all parties that have a lot to loose when things go wrong."}]}],"data":{"quirksMode":false}},"fields":{"layout":"post","slug":"/posts/3pc/"}}}]}},"pageContext":{}},"staticQueryHashes":[]}